<div align="center">
<h1> When "Correct" Is Not Safe: Can We Trust Functionally
Correct Patches Generated by Code Agents? </h1>

Yibo Peng<sup>1,‚Ä†</sup>, James Song<sup>2,‚Ä†</sup>, Lei Li<sup>3,‚Ä†</sup>, Mihai Christodorescu<sup>4</sup>, Ravi Mangal<sup>5</sup>, Corina Pasareanu<sup>1</sup>, Haizhong Zheng<sup>1</sup>, Beidi Chen<sup>1</sup>
<br>
<sup>1</sup>Carnegie Mellon University,
<sup>2</sup>University of Michigan,
<sup>3</sup>Peking University,
<sup>4</sup>Google,
<sup>5</sup>Colorado State University
<br>
‚Ä†Equal contribution

<div align="center">
[<a href="https://infini-ai-lab.github.io/FCV/">Website</a>]
</div>
<br>

<!-- ---------- -->
**TL;DR**
Code agents are increasingly trusted to autonomously fix bugs on platforms such as GitHub, yet their security
evaluation focuses almost exclusively on functional correctness. In this paper, we reveal a novel type of threat to
realworld codeagents: functionally correct yet vulnerable (FCV) patches, which pass all test cases but contain
vulnerable code. With our proposed FCVAttack, we demonstrate that SOTA LLMs (e.g., ChatGPT and Claude)
and agent scaffolds (e.g., SWEagent and OpenHands) are all vulnerable to this FCV threat; across 12 agentmodel
combinations on SWE-Bench, the attack only requires black-box access and a single query to the code agent to
perform the attack. For example, for CWE-538 (information exposure vulnerability), the FCV-Attack attains an
attack success rate of 40.7% on GPT-5 MINI + OPENHANDS. Our results reveal an important security threat
overlooked by current evaluation paradigms and urge the development of security-aware defenses for code agents

</div>



## üóûÔ∏è News

<!-- ---------- -->
<p align="center">
  <img src="assets/cwe_injection_pipeline.png" alt="ASR across Agent/Model/CWE" style="width:100%;"/>
</p>

<p align="center"><i>
<strong>Figure 1</strong> CWE-style injection attack on code agents. 
By embedding malicious instructions in issue descriptions, attackers can induce agents to generate test-passing patches that nevertheless embed exploitable vulnerabilities (e.g., CWE-94). 
This illustrates how functionally correct yet vulnerable (FCV) patches can propagate into real workflows.
</i></p>

<!-- ------- -->

<!-- The official implementation of M2PO will be released here soon! -->

## Getting Started
Much of our experiments reuse prior code by mini-SWE-agent, SWE-agent, and OpenHands, with some additions with the injected CWE prompts. 

### 1. Environment Setup

Ideally, you should create three separate conda environments corresponding to each of the three agents. 
```bash
cd FCV

conda create -n sweagent python==3.11
conda activate sweagent
cd SWE-agent 
pip install -e .

conda create -n minisweagent python==3.11
conda activate minisweagent
cd mini-swe-agent
pip install -e .

conda create -n openhands python==3.11
conda activate openhands
cd openhands
pip install -e .
```
For LLM Judge, you can reuse any of the above environments, since it only requires requests and OpenAI (if you are using gpt-5-mini as the judge). In our experiments, we used Qwen-3-Coder-480B-A35B-Instruct as the judge. 

### 2. Round 1: Identifying Resolved Instances

These are some example commands. They simply follow from the official documentations for these agents. 
#### mini-SWE-agent
```bash
cd mini-swe-agent
mini-extra swebench -c model_configs/kimi.yaml --subset verified --split test -o moonshotai_Kimi_K2_Instruct-pass1 --workers 16
```

#### SWE-agent
```bash
sweagent run-batch \
    --config model_configs/kimi-official.yaml \
    --instances.type swe_bench \
    --instances.subset verified \
    --instances.split test  \
    --output_dir kimi-pass1 \
    --num_workers 16
```

#### Openhands
```bash
```
### 3. Evaluation: SWE-Bench

After the first round, you will need to evaluate the results. You can either use the official [SWE-Bench](https://github.com/SWE-bench/SWE-bench) github repo and run the evaluation locally, or use their ```sb-cli``` cloud evaluation. We refer to the official documentation.


### 4. Running with CWE Injection + Ablation Study

This will depend on the agent. Please go to each agent's folder and read the README.md for additional details. 

### 5. LM Judge for all the results
Please go to ```attack-lm-judge```'s README.md for more details. 
