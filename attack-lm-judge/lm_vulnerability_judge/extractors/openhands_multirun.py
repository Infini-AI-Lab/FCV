"""
Extractor for OpenHands format outputs with multi-round support.
"""

import json
import glob
from typing import List, Dict, Any
from pathlib import Path

from .base import BaseExtractor, PatchInfo, FunctionalTestResult


class OpenHandsExtractor(BaseExtractor):
    """Extractor for OpenHands experiment outputs with multi-round support."""
    
    def __init__(self, config: Dict[str, Any]):
        """Initialize OpenHands extractor with round configuration."""
        super().__init__(config)
        self.start_round = config.get('start_round', 1)
        self.end_round = config.get('end_round', 1)
        self.base_path = Path(config.get('base_path', 'patch/openhands'))
        self.experiment_pattern = config.get('experiment_pattern', 'cwe_injection_experiments_*_round{round}')
        self.agent_path = config.get('agent_path', '')
    
    def extract_patches(self) -> List[PatchInfo]:
        """
        Extract patches from OpenHands eval_outputs across multiple rounds.
        
        Returns:
            List of PatchInfo objects from all specified rounds
        """
        all_patches = []
        
        for round_num in range(self.start_round, self.end_round + 1):
            round_patches = self._extract_patches_for_round(round_num)
            all_patches.extend(round_patches)
        
        return all_patches
    
    def _extract_patches_for_round(self, round_num: int) -> List[PatchInfo]:
        """Extract patches for a specific round."""
        patches = []
        
        # Build the path for this round
        experiment_pattern = self.experiment_pattern.format(round=round_num)
        agent_path = self.agent_path.format(round=round_num)
        
        # Find experiment directories matching the pattern
        experiment_dirs = glob.glob(str(self.base_path / experiment_pattern))
        
        for exp_dir in experiment_dirs:
            exp_path = Path(exp_dir)
            full_agent_path = exp_path / agent_path
            
            if not full_agent_path.exists():
                print(f"Warning: Agent path not found: {full_agent_path}")
                continue
            
            eval_outputs_dir = full_agent_path / "eval_outputs"
            if not eval_outputs_dir.exists():
                print(f"Warning: eval_outputs directory not found: {eval_outputs_dir}")
                continue
            
            # Extract patches from each instance directory
            for instance_dir in eval_outputs_dir.iterdir():
                if instance_dir.is_dir():
                    patch_file = instance_dir / "patch.diff"
                    
                    if patch_file.exists():
                        try:
                            with open(patch_file, 'r', encoding='utf-8') as f:
                                patch_content = f.read()
                            
                            if not self.validate_patch(patch_content):
                                continue
                            
                            # Parse file changes and patch size
                            changed_files, patch_size = self._parse_diff(patch_content)
                            
                            # Extract model name from metadata
                            model_name = self._extract_model_from_path(str(full_agent_path))
                            
                            patch_info = PatchInfo(
                                instance_id=instance_dir.name,
                                agent_name=self.agent_name,
                                model_name=model_name,
                                patch_content=patch_content,
                                is_functionally_correct=False,  # Will be set later
                                test_passed=False,  # Will be set later
                                file_changes=changed_files,
                                patch_size=patch_size,
                                metadata={
                                    'round': round_num,
                                    'experiment_path': str(exp_path),
                                    'agent_path': str(full_agent_path),
                                    'patch_file': str(patch_file)
                                }
                            )
                            
                            patches.append(patch_info)
                            
                        except Exception as e:
                            print(f"Warning: Failed to process patch file {patch_file}: {e}")
        
        return patches
    
    def extract_functional_tests(self) -> List[FunctionalTestResult]:
        """
        Extract functional test results from OpenHands reports across multiple rounds.
        
        Returns:
            List of FunctionalTestResult objects from all specified rounds
        """
        all_results = []
        
        for round_num in range(self.start_round, self.end_round + 1):
            round_results = self._extract_tests_for_round(round_num)
            all_results.extend(round_results)
        
        return all_results
    
    def _extract_tests_for_round(self, round_num: int) -> List[FunctionalTestResult]:
        """Extract test results for a specific round."""
        test_results = []
        
        # Build the path for this round
        experiment_pattern = self.experiment_pattern.format(round=round_num)
        agent_path = self.agent_path.format(round=round_num)
        
        # Find experiment directories matching the pattern
        experiment_dirs = glob.glob(str(self.base_path / experiment_pattern))
        
        for exp_dir in experiment_dirs:
            exp_path = Path(exp_dir)
            full_agent_path = exp_path / agent_path
            
            if not full_agent_path.exists():
                continue
            
            report_file = full_agent_path / "report.json"
            if not report_file.exists():
                print(f"Warning: Report file not found: {report_file}")
                continue
            
            try:
                with open(report_file, 'r', encoding='utf-8') as f:
                    report_data = json.load(f)
                
                # Extract resolved instances from OpenHands report
                resolved_instances = report_data.get('resolved_instances', [])
                completed_instances = report_data.get('completed_ids', [])
                
                # If resolved_instances is a number, get the list from resolved_ids
                if isinstance(resolved_instances, int):
                    resolved_instances = report_data.get('resolved_ids', [])
                
                # Create test results for resolved instances
                for instance_id in resolved_instances:
                    test_result = FunctionalTestResult(
                        instance_id=instance_id,
                        passed=True,
                        test_status='resolved',
                        metadata={
                            'round': round_num,
                            'source_file': str(report_file),
                            'experiment_path': str(exp_path),
                            'total_instances': report_data.get('total_instances', 0),
                            'resolved_count': len(resolved_instances),
                            **report_data
                        }
                    )
                    test_results.append(test_result)
                
                # Create test results for unresolved instances
                unresolved_instances = [
                    instance_id for instance_id in completed_instances 
                    if instance_id not in resolved_instances
                ]
                
                for instance_id in unresolved_instances:
                    test_result = FunctionalTestResult(
                        instance_id=instance_id,
                        passed=False,
                        test_status='unresolved',
                        metadata={
                            'round': round_num,
                            'source_file': str(report_file),
                            'experiment_path': str(exp_path),
                            'total_instances': report_data.get('total_instances', 0),
                            'resolved_count': len(resolved_instances),
                            **report_data
                        }
                    )
                    test_results.append(test_result)
                    
            except Exception as e:
                print(f"Warning: Failed to process OpenHands report file {report_file}: {e}")
        
        return test_results
    
    def _extract_model_from_path(self, path: str) -> str:
        """Extract model name from OpenHands directory path."""
        # Extract model name from path like "Qwen3-Coder-480B-A35B-Instruct_maxiter_100_N_cwe_532_injection_resolved_ids_round_1"
        path_parts = Path(path).name.split('_')
        for i, part in enumerate(path_parts):
            if 'Qwen' in part or 'GPT' in part or 'Claude' in part:
                # Find the model name part
                model_parts = []
                for j in range(i, len(path_parts)):
                    if path_parts[j] in ['maxiter', 'cwe', 'injection']:
                        break
                    model_parts.append(path_parts[j])
                return '_'.join(model_parts)
        
        return 'unknown'
    
    def get_round_statistics(self) -> Dict[str, Any]:
        """Get statistics for each round."""
        round_stats = {}
        
        for round_num in range(self.start_round, self.end_round + 1):
            patches = self._extract_patches_for_round(round_num)
            tests = self._extract_tests_for_round(round_num)
            
            # Match patches with test results
            test_map = {result.instance_id: result for result in tests}
            correct_patches = [
                patch for patch in patches 
                if test_map.get(patch.instance_id, None) and test_map[patch.instance_id].passed
            ]
            
            round_stats[f"round_{round_num}"] = {
                'total_patches': len(patches),
                'total_tests': len(tests),
                'functionally_correct': len(correct_patches),
                'success_rate': len(correct_patches) / len(patches) if patches else 0.0
            }
        
        return round_stats
