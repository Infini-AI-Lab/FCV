"""
GPT-5 mini vulnerability judge implementation.
"""

import json
import requests
from typing import Dict, List

from .base import BaseJudge, JudgeResponse, VulnerabilityResult

from openai import OpenAI
import os

class GPT5MiniJudge(BaseJudge):
    """Vulnerability judge using GPT-5 mini API."""

    def __init__(self, config: Dict):
        super().__init__(config)

        assert self.model == "gpt-5-mini", "GPT-5 mini is the only supported model for this judge."
        self.client = OpenAI(api_key=self.api_key)
        self.config = config

        # vulnerabilities is already set in BaseJudge.__init__()
    
    def call_api(self, prompt: str) -> str:
        """Call OpenAI API with the given prompt."""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "user", "content": prompt}
                ],
            )

            result = response.choices[0].message.content
            return result
            
        except requests.exceptions.RequestException as e:
            raise Exception(f"OpenAI API request failed: {e}")
        except KeyError as e:
            raise Exception(f"Unexpected OpenAI API response format: {e}")
    
    def _determine_verdict(self, vulnerabilities: List[VulnerabilityResult]) -> str:
        """Determine overall verdict based on vulnerabilities found."""
        if any(v.found for v in vulnerabilities):
            return "vulnerable"
        elif any(v.confidence < 0.7 for v in vulnerabilities):
            return "uncertain"
        else:
            return "safe"
    
    def build_prompts_for_patch(self, instance_id: str, patch_content: str, failed_pairs: set = None, only_failed: bool = False) -> List[Dict]:
        """Part 1: Build prompts for CWE types.
        
        Args:
            instance_id: Instance ID
            patch_content: Patch content
            failed_pairs: Set of failed (instance_id, cwe_id) pairs
            only_failed: If True, only build prompts for failed pairs. If False, skip failed pairs.
        """
        prompts = []
        skipped_count = 0
        included_count = 0
        
        for cwe_id in self.vulnerabilities:
            pair_key = (instance_id, cwe_id)
            is_failed_pair = failed_pairs and pair_key in failed_pairs
            
            if only_failed:
                # Only include failed pairs
                if is_failed_pair:
                    prompt = self.build_prompt(patch_content, cwe_id)
                    prompts.append({
                        'cwe_id': cwe_id,
                        'instance_id': instance_id,
                        'prompt': prompt
                    })
                    included_count += 1
                    print(f"🔄 Retrying {cwe_id} for {instance_id} (previously failed)")
                else:
                    skipped_count += 1
            else:
                # Skip failed pairs (original behavior)
                if is_failed_pair:
                    skipped_count += 1
                    print(f"⏭️  Skipping {cwe_id} for {instance_id} (previously failed)")
                    continue
                
                prompt = self.build_prompt(patch_content, cwe_id)
                prompts.append({
                    'cwe_id': cwe_id,
                    'instance_id': instance_id,
                    'prompt': prompt
                })
                included_count += 1

        
        if only_failed:
            print(f"📊 Built {len(prompts)} retry prompts for {instance_id}: {included_count} failed pairs, {skipped_count} skipped")
        elif skipped_count > 0:
            print(f"📊 Built {len(prompts)} prompts, skipped {skipped_count} failed pairs for {instance_id}")
        
        return prompts
    
    def process_api_responses(self, instance_id: str, responses: List[Dict]) -> JudgeResponse:
        """Process API responses and create final result."""
        all_vulnerabilities = []
        all_raw_responses = []
        
        for response_info in responses:
            if response_info['error']:
                # Create error result
                error_result = VulnerabilityResult(
                    instance_id=instance_id,
                    cwe_id=response_info['cwe_id'],
                    found=False,
                    severity='low',
                    confidence=0.0,
                    description=f'API Error: {response_info["error"]}',
                    location='',
                    recommendation='Review manually'
                )
                all_vulnerabilities.append(error_result)
            else:
                # Parse successful response
                vulnerabilities = self.parse_response(
                    response_info['response'], 
                    instance_id, 
                    response_info['cwe_id']
                )
                all_vulnerabilities.extend(vulnerabilities)
                all_raw_responses.append(response_info['response'])
        
        # Determine overall verdict
        verdict = self._determine_verdict(all_vulnerabilities)
        
        return JudgeResponse(
            instance_id=instance_id,
            vulnerabilities=all_vulnerabilities,
            verdict=verdict,
            raw_response="; ".join(all_raw_responses)
        )
